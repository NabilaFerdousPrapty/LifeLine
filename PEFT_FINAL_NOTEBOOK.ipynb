{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc959f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from peft) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from peft) (25.0)\n",
      "Requirement already satisfied: psutil in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from peft) (6.0.3)\n",
      "Requirement already satisfied: torch>=1.13.0 in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from peft) (2.5.1)\n",
      "Requirement already satisfied: transformers in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from peft) (4.57.3)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from peft) (1.12.0)\n",
      "Requirement already satisfied: safetensors in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from peft) (0.7.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from peft) (0.36.0)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2025.12.0)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.11.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from transformers->peft) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in d:\\anaconda\\envs\\tweet_project\\lib\\site-packages (from transformers->peft) (0.22.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install peft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7b01d8",
   "metadata": {},
   "source": [
    "The New \"LoRA-Powered\" Model Code\n",
    "Replace your Model Definition (Block 5) with this code. I have integrated LoRA specifically for CLIP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b2fa04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nabil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Device: cuda\n",
      "‚úÖ Setup & Preprocessing Function Ready!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# --- Text Preprocessing Imports ---\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Download stopwords once\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# --- 1. Setup Device ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üöÄ Device: {device}\")\n",
    "\n",
    "# --- 2. Define Preprocessing Function ---\n",
    "def preprocess_text(text):\n",
    "    text = str(text) \n",
    "    # 1. Removal of HTML\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    \n",
    "    # 2. To Lower Case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 3. Removal of URL\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # 4. Removal of Twitter Handles (@user)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    # 5. Removal of Hashtag symbol (keeping text)\n",
    "    text = re.sub(r'#', '', text) \n",
    "    \n",
    "    # 6. Removal of Placeholders\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "\n",
    "    # 7. Removal of Punctuation & Non-letter Characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # 8. Removal of Stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    # 9. Clean extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(\"‚úÖ Setup & Preprocessing Function Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42e6670e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading openai/clip-vit-base-patch32 with SafeTensors...\n",
      "üîì Unfreezing last 2 visual layers...\n",
      "üîì Unfreezing last 2 text layers...\n",
      "‚úÖ Model initialized with Deeper Fine-Tuning!\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# --- 5. Define the Fine-Tuning Model (Updated for Higher Accuracy) ---\n",
    "class MultimodalDisasterClassifier(nn.Module):\n",
    "    def __init__(self, model_id, num_classes=2):\n",
    "        super(MultimodalDisasterClassifier, self).__init__()\n",
    "        \n",
    "        print(f\"Loading {model_id} with SafeTensors...\")\n",
    "        self.clip = CLIPModel.from_pretrained(model_id, use_safetensors=True)\n",
    "        \n",
    "        # Increased capacity in the head (Standard 512 -> 256 -> 2)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),   # Added BatchNorm for stability\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),       # Increased Dropout to 0.3\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, pixel_values):\n",
    "        text_out = self.clip.get_text_features(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        img_out = self.clip.get_image_features(pixel_values=pixel_values)\n",
    "        \n",
    "        # Normalize\n",
    "        text_out = text_out / text_out.norm(dim=-1, keepdim=True)\n",
    "        img_out = img_out / img_out.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        combined = torch.cat((img_out, text_out), dim=1)\n",
    "        logits = self.classifier(combined.float())\n",
    "        return logits\n",
    "\n",
    "# Initialize\n",
    "model_id = \"openai/clip-vit-base-patch32\"\n",
    "model = MultimodalDisasterClassifier(model_id).to(device)\n",
    "\n",
    "# --- ADVANCED UNFREEZING LOGIC ---\n",
    "# 1. Freeze everything\n",
    "for param in model.clip.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. Unfreeze Classifier\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 3. Unfreeze LAST 2 LAYERS of Vision & Text Encoders (Deeper adaptation)\n",
    "# Note: 'layers' index allows slicing. [-2:] means the last 2 blocks.\n",
    "print(\"üîì Unfreezing last 2 visual layers...\")\n",
    "for layer in model.clip.vision_model.encoder.layers[-2:]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "print(\"üîì Unfreezing last 2 text layers...\")\n",
    "for layer in model.clip.text_model.encoder.layers[-2:]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "print(\"‚úÖ Model initialized with Deeper Fine-Tuning!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fae71f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading openai/clip-vit-base-patch32 with SafeTensors...\n",
      "‚úÖ LoRA Adapters Injected successfully!\n",
      "trainable params: 1,966,080 || all params: 153,243,393 || trainable%: 1.2830\n",
      "üöÄ Model is ready for LoRA Fine-Tuning!\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "\n",
    "# --- 5. Define the LoRA-Enhanced Model ---\n",
    "class MultimodalLoRAClassifier(nn.Module):\n",
    "    def __init__(self, model_id, num_classes=2):\n",
    "        super(MultimodalLoRAClassifier, self).__init__()\n",
    "        \n",
    "        print(f\"Loading {model_id} with SafeTensors...\")\n",
    "        # 1. Load Base Model\n",
    "        self.clip = CLIPModel.from_pretrained(model_id, use_safetensors=True)\n",
    "        \n",
    "        # 2. Apply LoRA Configuration\n",
    "        # We target the \"Query\" and \"Value\" matrices in the Attention blocks\n",
    "        # This is where the model learns relationships between words and image patches.\n",
    "        config = LoraConfig(\n",
    "            r=32,                   # Rank (Higher = smarter but heavier. 16-64 is standard)\n",
    "            lora_alpha=64,          # Scaling factor (usually 2x Rank)\n",
    "            target_modules=[\"q_proj\", \"v_proj\"], # Apply LoRA to attention layers\n",
    "            lora_dropout=0.1,       # Helps prevent overfitting\n",
    "            bias=\"none\"\n",
    "        )\n",
    "        \n",
    "        # Wrap the CLIP model with LoRA\n",
    "        self.clip = get_peft_model(self.clip, config)\n",
    "        print(\"‚úÖ LoRA Adapters Injected successfully!\")\n",
    "        self.clip.print_trainable_parameters() # Show supervisor how efficient it is\n",
    "        \n",
    "        # 3. The Classifier Head (Remains Full Trainable)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),    # Added Batch Norm for 90% push\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),        # High Dropout to force generalization\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, pixel_values):\n",
    "        # 1. Extract Features (LoRA active here)\n",
    "        text_out = self.clip.get_text_features(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        img_out = self.clip.get_image_features(pixel_values=pixel_values)\n",
    "        \n",
    "        # 2. Normalize\n",
    "        text_out = text_out / text_out.norm(dim=-1, keepdim=True)\n",
    "        img_out = img_out / img_out.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        # 3. Fusion\n",
    "        combined = torch.cat((img_out, text_out), dim=1)\n",
    "        \n",
    "        # 4. Classification\n",
    "        return self.classifier(combined.float())\n",
    "\n",
    "# Initialize\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultimodalLoRAClassifier(\"openai/clip-vit-base-patch32\").to(device)\n",
    "\n",
    "print(\"üöÄ Model is ready for LoRA Fine-Tuning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865bab28",
   "metadata": {},
   "source": [
    "The Updated Training Loop\n",
    "Because LoRA handles the freezing internally, the training loop is actually simpler. You don't need manual unfreezing loops anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60293c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Device: cuda\n",
      "‚úÖ Setup & Preprocessing Function Ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nabil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# --- Text Preprocessing Imports ---\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Download stopwords once\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# --- 1. Setup Device ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üöÄ Device: {device}\")\n",
    "\n",
    "# --- 2. Define Preprocessing Function ---\n",
    "def preprocess_text(text):\n",
    "    text = str(text) \n",
    "    # 1. Removal of HTML\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    \n",
    "    # 2. To Lower Case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 3. Removal of URL\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # 4. Removal of Twitter Handles (@user)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    # 5. Removal of Hashtag symbol (keeping text)\n",
    "    text = re.sub(r'#', '', text) \n",
    "    \n",
    "    # 6. Removal of Placeholders\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "\n",
    "    # 7. Removal of Punctuation & Non-letter Characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # 8. Removal of Stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    # 9. Clean extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(\"‚úÖ Setup & Preprocessing Function Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e69206e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Class Defined!\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Define Custom Dataset Class ---\n",
    "class CrisisDataset(Dataset):\n",
    "    def __init__(self, df, processor, data_path=\".\"):\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = row['tweet_text']\n",
    "        label = row['label']\n",
    "        img_path = os.path.join(self.data_path, row['image'])\n",
    "        \n",
    "        try:\n",
    "            # Load and convert image\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            \n",
    "            # CLIP Processor handles Image Resizing/Norm + Text Tokenization\n",
    "            encoding = self.processor(\n",
    "                text=text, \n",
    "                images=image, \n",
    "                return_tensors=\"pt\", \n",
    "                padding=\"max_length\", \n",
    "                truncation=True, \n",
    "                max_length=77\n",
    "            )\n",
    "            \n",
    "            # Remove batch dimension added by processor\n",
    "            return {\n",
    "                'pixel_values': encoding['pixel_values'].squeeze(0),\n",
    "                'input_ids': encoding['input_ids'].squeeze(0),\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "                'label': torch.tensor(label, dtype=torch.long)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            # If an image fails, return the next one (simple error handling)\n",
    "            return self.__getitem__((idx + 1) % len(self.df))\n",
    "\n",
    "print(\"‚úÖ Dataset Class Defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a63629e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Applying Text Preprocessing (Steps 1-9)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13608/13608 [00:01<00:00, 13486.48it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2237/2237 [00:00<00:00, 13318.07it/s]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Ready! Train: 13608, Test: 2237\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Load & Clean Data ---\n",
    "# Define paths (Adjust these to match your folder structure)\n",
    "train_path = os.path.join(\"data/CrisisMMD/crisismmd_datasplit_all/crisismmd_datasplit_all/task_informative_text_img_train.tsv\")\n",
    "test_path = os.path.join(\"data/CrisisMMD/crisismmd_datasplit_all/crisismmd_datasplit_all/task_informative_text_img_test.tsv\")\n",
    "\n",
    "# Load DataFrames\n",
    "train_df = pd.read_csv(train_path, sep='\\t')\n",
    "test_df = pd.read_csv(test_path, sep='\\t')\n",
    "\n",
    "# Function to encode labels\n",
    "def encode_label(row):\n",
    "    if row['label_image'] == 'informative': return 1\n",
    "    elif row['label_image'] == 'not_informative': return 0\n",
    "    return None\n",
    "\n",
    "# Apply Label Encoding\n",
    "train_df['label'] = train_df.apply(encode_label, axis=1)\n",
    "test_df['label'] = test_df.apply(encode_label, axis=1)\n",
    "\n",
    "# Drop NaNs\n",
    "train_df = train_df.dropna(subset=['label'])\n",
    "test_df = test_df.dropna(subset=['label'])\n",
    "train_df['label'] = train_df['label'].astype(int)\n",
    "test_df['label'] = test_df['label'].astype(int)\n",
    "\n",
    "# --- APPLY PREPROCESSING HERE ---\n",
    "print(\"‚è≥ Applying Text Preprocessing (Steps 1-9)...\")\n",
    "tqdm.pandas() # Progress bar\n",
    "train_df['tweet_text'] = train_df['tweet_text'].progress_apply(preprocess_text)\n",
    "test_df['tweet_text'] = test_df['tweet_text'].progress_apply(preprocess_text)\n",
    "\n",
    "# Initialize Processor\n",
    "model_id = \"openai/clip-vit-base-patch32\"\n",
    "processor = CLIPProcessor.from_pretrained(model_id)\n",
    "\n",
    "# Create Datasets & Loaders\n",
    "batch_size = 32 # Keep small for GPU memory\n",
    "train_dataset = CrisisDataset(train_df, processor)\n",
    "test_dataset = CrisisDataset(test_df, processor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"‚úÖ Data Ready! Train: {len(train_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcc86aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading openai/clip-vit-base-patch32 with SafeTensors...\n",
      "üîì Unfreezing last 2 visual layers...\n",
      "üîì Unfreezing last 2 text layers...\n",
      "‚úÖ Model initialized with Deeper Fine-Tuning!\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Define the Fine-Tuning Model (Updated for Higher Accuracy) ---\n",
    "class MultimodalDisasterClassifier(nn.Module):\n",
    "    def __init__(self, model_id, num_classes=2):\n",
    "        super(MultimodalDisasterClassifier, self).__init__()\n",
    "        \n",
    "        print(f\"Loading {model_id} with SafeTensors...\")\n",
    "        self.clip = CLIPModel.from_pretrained(model_id, use_safetensors=True)\n",
    "        \n",
    "        # Increased capacity in the head (Standard 512 -> 256 -> 2)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),   # Added BatchNorm for stability\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),       # Increased Dropout to 0.3\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, pixel_values):\n",
    "        text_out = self.clip.get_text_features(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        img_out = self.clip.get_image_features(pixel_values=pixel_values)\n",
    "        \n",
    "        # Normalize\n",
    "        text_out = text_out / text_out.norm(dim=-1, keepdim=True)\n",
    "        img_out = img_out / img_out.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        combined = torch.cat((img_out, text_out), dim=1)\n",
    "        logits = self.classifier(combined.float())\n",
    "        return logits\n",
    "\n",
    "# Initialize\n",
    "model_id = \"openai/clip-vit-base-patch32\"\n",
    "model = MultimodalDisasterClassifier(model_id).to(device)\n",
    "\n",
    "# --- ADVANCED UNFREEZING LOGIC ---\n",
    "# 1. Freeze everything\n",
    "for param in model.clip.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. Unfreeze Classifier\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 3. Unfreeze LAST 2 LAYERS of Vision & Text Encoders (Deeper adaptation)\n",
    "# Note: 'layers' index allows slicing. [-2:] means the last 2 blocks.\n",
    "print(\"üîì Unfreezing last 2 visual layers...\")\n",
    "for layer in model.clip.vision_model.encoder.layers[-2:]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "print(\"üîì Unfreezing last 2 text layers...\")\n",
    "for layer in model.clip.text_model.encoder.layers[-2:]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "print(\"‚úÖ Model initialized with Deeper Fine-Tuning!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22c52a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Advanced Training for 10 Epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  13%|‚ñà‚ñé        | 57/426 [01:16<08:40,  1.41s/it, loss=0.675]d:\\Anaconda\\envs\\tweet_project\\lib\\site-packages\\PIL\\Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [10:52<00:00,  1.53s/it, loss=0.334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Train Loss: 0.5067 | üìà Val Acc: 0.8900\n",
      "üíæ New Best Model Saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [05:41<00:00,  1.25it/s, loss=0.233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Train Loss: 0.3856 | üìà Val Acc: 0.8887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [05:39<00:00,  1.25it/s, loss=0.404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Train Loss: 0.3623 | üìà Val Acc: 0.8865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [05:38<00:00,  1.26it/s, loss=0.219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Train Loss: 0.3404 | üìà Val Acc: 0.8873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [08:24<00:00,  1.18s/it, loss=0.346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Train Loss: 0.3213 | üìà Val Acc: 0.8878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [05:56<00:00,  1.19it/s, loss=0.361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Train Loss: 0.3086 | üìà Val Acc: 0.8878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [09:38<00:00,  1.36s/it, loss=0.326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Train Loss: 0.2950 | üìà Val Acc: 0.8887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [11:51<00:00,  1.67s/it, loss=0.367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Train Loss: 0.2857 | üìà Val Acc: 0.8869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [15:49<00:00,  2.23s/it, loss=0.214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Train Loss: 0.2768 | üìà Val Acc: 0.8865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [06:52<00:00,  1.03it/s, loss=0.371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Train Loss: 0.2721 | üìà Val Acc: 0.8865\n",
      "\n",
      "üèÜ Loading Best Model (Acc: 0.8900)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nabil\\AppData\\Local\\Temp\\ipykernel_18296\\3117315705.py:95: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_vlm_model.pth\"))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# --- 6. Advanced Training Loop ---\n",
    "\n",
    "# A. Hyperparameters\n",
    "EPOCHS = 10  # Increased epochs (Early stopping will catch the best one)\n",
    "BATCH_SIZE = 32\n",
    "learning_rate = 2e-5 # Slightly higher starting rate for Scheduler to manage\n",
    "\n",
    "# B. Optimizer & Scheduler\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': model.clip.parameters(), 'lr': 1e-6}, # Backbone stays slow\n",
    "    {'params': model.classifier.parameters(), 'lr': 1e-4} # Head learns fast\n",
    "], weight_decay=0.01) # Increased weight decay\n",
    "\n",
    "# Total steps = (batches per epoch) * epochs\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "\n",
    "# Linear Scheduler with Warmup (Standard for Transformers)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=int(0.1 * total_steps), # Warmup for first 10%\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Label Smoothing Loss (Helps with noisy labels)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# C. Training with Validation Tracking\n",
    "print(f\"üöÄ Starting Advanced Training for {EPOCHS} Epochs...\")\n",
    "\n",
    "best_acc = 0.0\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # --- TRAIN ---\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    \n",
    "    for batch in loop:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        pixel_values = batch['pixel_values'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask, pixel_values)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient Clipping (Prevents exploding gradients)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step() # Update learning rate\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # --- VALIDATION (Check performance after every epoch) ---\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            pixel_values = batch['pixel_values'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, pixel_values)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "    val_acc = correct / total\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    print(f\"üìâ Train Loss: {avg_train_loss:.4f} | üìà Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Save Best Model\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_vlm_model.pth\")\n",
    "        print(\"üíæ New Best Model Saved!\")\n",
    "\n",
    "# D. Load the Best Model for Final Evaluation\n",
    "print(f\"\\nüèÜ Loading Best Model (Acc: {best_acc:.4f})...\")\n",
    "model.load_state_dict(torch.load(\"best_vlm_model.pth\"))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, label='Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(val_accuracies, label='Accuracy', color='green')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9eaa8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading openai/clip-vit-base-patch32 with SafeTensors...\n",
      "trainable params: 5,898,240 || all params: 157,767,299 || trainable%: 3.7386\n",
      "üöÄ Training with Optimized LoRA started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [14:05<00:00,  1.98s/it, loss=0.2182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Loss: 0.4224 | üìà Val Acc: 0.8069\n",
      "‚≠ê Saved New Best Accuracy!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [08:23<00:00,  1.18s/it, loss=0.2254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Loss: 0.3723 | üìà Val Acc: 0.8605\n",
      "‚≠ê Saved New Best Accuracy!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [07:40<00:00,  1.08s/it, loss=0.2066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Loss: 0.3530 | üìà Val Acc: 0.8315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [07:43<00:00,  1.09s/it, loss=0.2809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Loss: 0.3494 | üìà Val Acc: 0.8315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [07:42<00:00,  1.09s/it, loss=0.3298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Loss: 0.3649 | üìà Val Acc: 0.8212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [07:40<00:00,  1.08s/it, loss=0.2688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Loss: 0.3778 | üìà Val Acc: 0.8114\n",
      "üõë Stopping Early. Best Accuracy: 0.8605\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- A. RE-INITIALIZE YOUR BASE MODEL (CRITICAL) ---\n",
    "# RESTART YOUR KERNEL BEFORE RUNNING THIS.\n",
    "# Replace \"your-model-id-here\" with your actual model path (e.g., \"openai/clip-vit-base-patch32\")\n",
    "MODEL_ID = \"openai/clip-vit-base-patch32\" # <-- UPDATE THIS ACCORDING TO YOUR THESIS CODE\n",
    "\n",
    "model = MultimodalDisasterClassifier(model_id=MODEL_ID, num_classes=2) \n",
    "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "# --- B. DEFINE HELPERS ---\n",
    "class MockConfig:\n",
    "    def __init__(self):\n",
    "        self.tie_word_embeddings = False\n",
    "        self.use_return_dict = False\n",
    "    def get(self, key, default=None):\n",
    "        return getattr(self, key, default)\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=4):\n",
    "        self.patience, self.counter, self.best_acc, self.early_stop = patience, 0, 0.0, False\n",
    "    def __call__(self, val_acc):\n",
    "        if val_acc > self.best_acc:\n",
    "            self.best_acc, self.counter = val_acc, 0\n",
    "            return True\n",
    "        self.counter += 1\n",
    "        if self.counter >= self.patience: self.early_stop = True\n",
    "        return False\n",
    "\n",
    "# --- C. APPLY CLEAN LoRA ---\n",
    "model.config = MockConfig()\n",
    "lora_config = LoraConfig(\n",
    "    r=64, \n",
    "    lora_alpha=128, \n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"], \n",
    "    lora_dropout=0.1, \n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "# \n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# --- D. TRAINING SETUP ---\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.01)\n",
    "early_stopper = EarlyStopper(patience=4)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "\n",
    "# --- E. THE LOOP ---\n",
    "print(\"üöÄ Training with Optimized LoRA started...\")\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    for batch in loop:\n",
    "        ids, mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
    "        pixels, labels = batch['pixel_values'].to(device), batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: keywords fix the argument errors\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, pixel_values=pixels)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            v_ids, v_mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
    "            v_pixels, v_labels = batch['pixel_values'].to(device), batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=v_ids, attention_mask=v_mask, pixel_values=v_pixels)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == v_labels).sum().item()\n",
    "            total += v_labels.size(0)\n",
    "            \n",
    "    val_acc = correct / total\n",
    "    print(f\"üìâ Loss: {total_loss/len(train_loader):.4f} | üìà Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if early_stopper(val_acc):\n",
    "        torch.save(model.state_dict(), \"best_lora_model.pth\")\n",
    "        print(\"‚≠ê Saved New Best Accuracy!\")\n",
    "\n",
    "    if early_stopper.early_stop:\n",
    "        print(f\"üõë Stopping Early. Best Accuracy: {early_stopper.best_acc:.4f}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9407c68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading openai/clip-vit-base-patch32 with SafeTensors...\n",
      "trainable params: 5,898,240 || all params: 157,767,299 || trainable%: 3.7386\n",
      "üöÄ Starting High-Performance LoRA Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [10:23<00:00,  1.46s/it, loss=0.2707, lr=6.67e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 1 Avg Loss: 0.5516 | üìà Val Acc: 0.8686\n",
      "‚≠ê NEW RECORD: Saved Best LoRA Model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [10:21<00:00,  1.46s/it, loss=0.3607, lr=9.63e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 2 Avg Loss: 0.3706 | üìà Val Acc: 0.8713\n",
      "‚≠ê NEW RECORD: Saved Best LoRA Model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [17:24<00:00,  2.45s/it, loss=0.4088, lr=8.89e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 3 Avg Loss: 0.3017 | üìà Val Acc: 0.8690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [12:56<00:00,  1.82s/it, loss=0.2460, lr=8.15e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 4 Avg Loss: 0.2540 | üìà Val Acc: 0.8672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [14:27<00:00,  2.04s/it, loss=0.2460, lr=7.41e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 5 Avg Loss: 0.2237 | üìà Val Acc: 0.8619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [10:28<00:00,  1.48s/it, loss=0.2373, lr=6.67e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 6 Avg Loss: 0.2117 | üìà Val Acc: 0.8449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 426/426 [14:57<00:00,  2.11s/it, loss=0.4257, lr=5.93e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìâ Epoch 7 Avg Loss: 0.2039 | üìà Val Acc: 0.8578\n",
      "üõë Overfitting detected. Best Accuracy: 0.8713\n",
      "\n",
      "üèÜ Final Accuracy: 0.8713\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. MODEL INITIALIZATION ---\n",
    "\n",
    "MODEL_ID = \"openai/clip-vit-base-patch32\"\n",
    "\n",
    "model = MultimodalDisasterClassifier(model_id=MODEL_ID, num_classes=2) \n",
    "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "# --- 2. HELPERS & COMPATIBILITY ---\n",
    "class MockConfig:\n",
    "    def __init__(self):\n",
    "        self.tie_word_embeddings = False\n",
    "        self.use_return_dict = False\n",
    "    def get(self, key, default=None):\n",
    "        return getattr(self, key, default)\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=5): # Slightly more patience for scheduler to work\n",
    "        self.patience, self.counter, self.best_acc, self.early_stop = patience, 0, 0.0, False\n",
    "    def __call__(self, val_acc):\n",
    "        if val_acc > self.best_acc:\n",
    "            self.best_acc, self.counter = val_acc, 0\n",
    "            return True\n",
    "        self.counter += 1\n",
    "        if self.counter >= self.patience: self.early_stop = True\n",
    "        return False\n",
    "\n",
    "# --- 3. APPLY LoRA ---\n",
    "model.config = MockConfig()\n",
    "lora_config = LoraConfig(\n",
    "    r=64, \n",
    "    lora_alpha=128, \n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"], \n",
    "    lora_dropout=0.1, \n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "# \n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# --- 4. OPTIMIZER & SCHEDULER SETUP ---\n",
    "# We use a lower LR (1e-4) to prevent the \"accuracy crash\" seen in your logs\n",
    "EPOCHS = 15\n",
    "LR = 1e-4 \n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=0.05)\n",
    "\n",
    "# Warmup helps the LoRA adapters stabilize before aggressive learning\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=int(0.1 * total_steps), \n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Label smoothing (0.05) is the key to generalizing on CrisisMMD images\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "early_stopper = EarlyStopper(patience=5)\n",
    "\n",
    "# --- 5. THE OPTIMIZED TRAINING LOOP ---\n",
    "print(f\"üöÄ Starting High-Performance LoRA Training...\")\n",
    "\n",
    "best_acc = 0.0\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    \n",
    "    for batch in loop:\n",
    "        ids = batch['input_ids'].to(device)\n",
    "        mask = batch['attention_mask'].to(device)\n",
    "        pixels = batch['pixel_values'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Keyword arguments avoid the TypeError from previous attempts\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, pixel_values=pixels)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step() # Critical: Updates LR every batch\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=f\"{loss.item():.4f}\", lr=f\"{scheduler.get_last_lr()[0]:.2e}\")\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            v_ids, v_mask = batch['input_ids'].to(device), batch['attention_mask'].to(device)\n",
    "            v_pixels, v_labels = batch['pixel_values'].to(device), batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=v_ids, attention_mask=v_mask, pixel_values=v_pixels)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == v_labels).sum().item()\n",
    "            total += v_labels.size(0)\n",
    "            \n",
    "    val_acc = correct / total\n",
    "    print(f\"üìâ Epoch {epoch+1} Avg Loss: {total_loss/len(train_loader):.4f} | üìà Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # --- Save & Early Stop ---\n",
    "    if early_stopper(val_acc):\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_lora_90plus.pth\")\n",
    "        print(\"‚≠ê NEW RECORD: Saved Best LoRA Model!\")\n",
    "\n",
    "    if early_stopper.early_stop:\n",
    "        print(f\"üõë Overfitting detected. Best Accuracy: {best_acc:.4f}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nüèÜ Final Accuracy: {best_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweet_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
